Molecular dynamics (MD) is a standard technique to study the movement of atoms in a substance over time. It involves computing the forces on all atoms for every time step as a product of the bonded and non-bonded interactions. This is done by numerically solving the Newton's law of motions and update the parameters such as velocity and position of each atom. Computing the forces from non-bonded interactions is computationally expensive and our conventional multicore processors falls behind on the computational requirements. There has been numerous efforts going in this area to accelerate MD simulations \michael{which we take up in this work}.
%especially the ones based on graphics processing unit (GPU) and field-programmable gate array (FPGA).   

\iffalse
Microchips sizes of FPGA and GPU, are on a constant decline to accommodate more transistors but it also makes the transistors susceptible to both temporary and permanent failures. These hardware faults occasionally propagate to the software and considering this aspect, there is a renewed interest in approximate computing that can be applied in the software to give us the outputs that does not diverge too much from the ideal outputs. Approximate computing also ensures that the portion of investment needed in detecting the hardware faults, avoidance and recovery is avoided.
\fi

\michael{
For a long time newly developed microchips became faster and more efficient over time due to new manufacturing processes and shrinking semiconductor scales. However, this development slowly comes to an end as scaling down the structures of silicon based chips becomes more and more difficult. The focus therefore shifts towards making efficient use of the available technology.}

\michael{One approach is the use of Approximate Computing~\cite{KlavikMalossiBekasEtAl2014}.}
The research goal of Approximate Computing is to explore techniques to gain more efficiency by relaxing the exactness of calculated outputs compared to the ideal outputs.
\michael{Another approach is the use of accelerator hardware in the form of graphics processing units (GPUs), application-specific integrated circuits (ASICs) or field-programmable gate arrays (FPGAs). While the use of GPUs for scientific applications is relatively wide-spread, the use of ASICs and FPGAs is less common but gained attention over the last years.}

\michael{
A basic method of approximation and a key requirement for efficient use of processing hardware is the use of adequate data widths in computationally intensive kernels. While in many scientific applications the use of double precision floating-point is most common, this precision is not always required. For example, iterative methods can exhibit resilience against low precision arithmetic~\cite{lass17-esl}. Mainly driven by the growing popularity of artificial neural networks (ANNs), we can observe growing support of low-precision data types, such as half-precision floating point and bfloat16, in hardware accelerators. With programmable hardware like FPGAs even arbitrary data types can be throught of and used.
}

\michael{In this paper, we demonstrate the resilience of MD, simulating the use of low-precision data types. By this, we lay the foundation for the development of efficient MD accelerators. Due to the possible use of custom data types on FPGAs, we see them as main target technology for our work.}

%In this paper, we describe one such technique that relaxes the exactness of the output and we explore to what extent it diverges from the ideal output.
